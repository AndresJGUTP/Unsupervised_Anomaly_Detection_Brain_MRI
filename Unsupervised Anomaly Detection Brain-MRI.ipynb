{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Unsupervised Anomaly Detection Brain-MRI.ipynb",
   "provenance": [
    {
     "file_id": "1SnihwKuEnP605BZEL1vdlGPA_xM6Bpgk",
     "timestamp": 1567420278659
    },
    {
     "file_id": "1Y14H2kevErX7LCln3-8yHXNQtnykb3m9",
     "timestamp": 1566387374003
    }
   ],
   "collapsed_sections": [
    "1-a9c5c4qaiK",
    "P2WmjqCqp3S4",
    "9Oc6ISRcqJMI",
    "qdIb36bv-yji",
    "U0D7zuB62DR0"
   ],
   "toc_visible": true,
   "machine_shape": "hm"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6cjIFrxl4xpb",
    "colab_type": "text"
   },
   "source": [
    "# Unsupervised Anomaly Detection Brain-MRI\n",
    "\n",
    "Jupyter notebook for running all the experiments from our [paper](https://arxiv.org/abs/2004.03271). \n",
    "\n",
    "Hyperparameters may have to be adjusted!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xYcltK7e6r5A",
    "colab_type": "text"
   },
   "source": [
    "## Preperation\n",
    "\n",
    "### Imports and installation of the required libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "LI-mX3ic4zBC",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "from google.colab import drive\n",
    "from google.colab import files\n",
    "import os, glob\n",
    "! pip install pynrrd\n",
    "! pip install SimpleITK\n",
    "! pip install bunch\n",
    "! pip install nibabel\n",
    "! pip install medpy"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xlBFG8cb9zRr",
    "colab_type": "text"
   },
   "source": [
    "### Get Code\n",
    "Clone Code from github.com"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "BmL1urt8-F1a",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "! git clone https://github.com/StefanDenn3r/Unsupervised_Anomaly_Detection_Brain_MRI\n",
    "! cd Unsupervised_Anomaly_Detection_Brain_MRI/"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uo5Rut3WcSHH",
    "colab_type": "text"
   },
   "source": [
    "### Google Drive mount\n",
    "Mounting Google Drive to access datasets."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "hBFA_7f5cUe0",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "drive.mount('gdrive')"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wRn8HOi7rSvV",
    "colab_type": "text"
   },
   "source": [
    "### Tensorboard and tunneling\n",
    "Install ngrok for tunneling "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "sc71w6qerQtF",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "if os.path.exists(\"ngrok-stable-linux-amd64.zip\"):\n",
    "  os.remove(\"ngrok-stable-linux-amd64.zip\")\n",
    "\n",
    "if os.path.exists(\"ngrok\"):\n",
    "  os.remove(\"ngrok\")\n",
    "  \n",
    "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
    "!unzip ngrok-stable-linux-amd64.zip"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wQ6JZY18fS4G",
    "colab_type": "text"
   },
   "source": [
    "Start tensorboard and forward port with ngrok"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Kele9MJBfAVK",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "LOG_DIR = 'logs/'\n",
    "get_ipython().system_raw(\n",
    "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
    "    .format(LOG_DIR)\n",
    ")\n",
    "\n",
    "get_ipython().system_raw('./ngrok http 6006 &')"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8fGr1nvVqduU",
    "colab_type": "text"
   },
   "source": [
    "Extract ngrok url for accessing tensorboard\n",
    "\n",
    "**Attention**: Sometimes it throws an error like this:\n",
    "```\n",
    "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
    "```\n",
    "If this is the case the easiest way to solve this issue is to delete the ngrok*.zip and ngrok from the Google Drive folder and install them again.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "rOJxnfekqPg2",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "! curl -s http://localhost:4040/api/tunnels | python3 -c \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o8QsqbYA53MI",
    "colab_type": "text"
   },
   "source": [
    "## Training\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "m1xgAd-K4Q30",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "%tensorflow_version 1.x \n",
    "import json\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from datetime import datetime\n",
    "from utils.default_config_setup import get_config, get_options, get_datasets\n",
    "from trainers.AE import AE\n",
    "from trainers.VAE import VAE\n",
    "from trainers.CE import CE\n",
    "from trainers.ceVAE import ceVAE\n",
    "from trainers.VAE_You import VAE_You\n",
    "from trainers.GMVAE import GMVAE\n",
    "from trainers.GMVAE_spatial import GMVAE_spatial\n",
    "from trainers.fAnoGAN import fAnoGAN\n",
    "from trainers.ConstrainedAAE import ConstrainedAAE\n",
    "from trainers.ConstrainedAE import ConstrainedAE\n",
    "from trainers.AnoVAEGAN import AnoVAEGAN\n",
    "from models import autoencoder, variational_autoencoder, context_encoder_variational_autoencoder, variational_autoencoder_Zimmerer, context_encoder_variational_autoencoder, context_encoder_variational_autoencoder_Zimmerer,  gaussian_mixture_variational_autoencoder_You, gaussian_mixture_variational_autoencoder_spatial, gaussian_mixture_variational_autoencoder, fanogan, fanogan_schlegl, constrained_autoencoder, constrained_adversarial_autoencoder, constrained_adversarial_autoencoder_Chen, anovaegan\n",
    "from utils import Evaluation\n",
    "from utils.default_config_setup import get_config, get_options, get_datasets, Dataset\n"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xogLARJl_B0K",
    "colab_type": "text"
   },
   "source": [
    "Set paths to datasets and where to save checkpoints and evaluations."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "GgkGf2LO35hI",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "def get_CONFIG(timestamp=None):\n",
    "  current_time = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "  if timestamp:\n",
    "    current_time=timestamp\n",
    "  dataset_root = \"/content/gdrive/data\"\n",
    "  save_dir = \"/content/gdrive/saved\"\n",
    "  CONFIG = {\n",
    "    \"BRAINWEBDIR\": os.path.join(dataset_root, 'Brainweb'),\n",
    "    \"MSSEG2008DIR\": os.path.join(dataset_root, 'MSSEG2008'),\n",
    "    \"MSISBI2015DIR\": os.path.join(dataset_root, 'ISBIMSlesionChallenge'),\n",
    "    \"MSLUBDIR\": os.path.join(dataset_root, 'MSlub'),\n",
    "    \"CHECKPOINTDIR\": os.path.join(save_dir, 'checkpoints', current_time),\n",
    "    \"SAMPLEDIR\": os.path.join(save_dir, 'sample_dir', current_time),\n",
    "  }\n",
    "  return CONFIG"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L41jcwBrqkev",
    "colab_type": "text"
   },
   "source": [
    "### Manual Training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1-a9c5c4qaiK",
    "colab_type": "text"
   },
   "source": [
    "#### Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Q8IFuKHqEiI",
    "colab_type": "text"
   },
   "source": [
    "**AE**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "IBobdPWvXBsl",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "tf.reset_default_graph()\n",
    "dataset = Dataset.BRAINWEB\n",
    "options = get_options(batchsize=128, learningrate=0.0001, numEpochs=20, zDim=128, outputWidth=128, outputHeight=128, config=get_CONFIG())\n",
    "options['data']['dir'] = options[\"globals\"][dataset.value]\n",
    "datasetHC, datasetPC = get_datasets(options, dataset)\n",
    "config = get_config(trainer=AE, options=options, optimizer='ADAM', intermediateResolutions=[8, 8], dropout_rate=0.1, dataset=datasetHC)\n",
    "\n",
    "# Create an instance of the model and train it\n",
    "model = AE(tf.Session(), config, network=autoencoder.autoencoder)\n",
    "\n",
    "# Train it\n",
    "model.train(datasetHC)\n",
    "\n",
    "# Evaluate\n",
    "Evaluation.evaluate(datasetPC, model, options, description=f\"{type(datasetHC).__name__}-{options['threshold']}\", epoch=str(options['train']['numEpochs']))\n"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E-pIg1uHQufK",
    "colab_type": "text"
   },
   "source": [
    "**VAE**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Ia25A9wli8d6",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "tf.reset_default_graph()\n",
    "dataset = Dataset.BRAINWEB\n",
    "options = get_options(batchsize=128, learningrate=0.0001, numEpochs=20, zDim=128, outputWidth=128, outputHeight=128, config=get_CONFIG())\n",
    "options['data']['dir'] = options[\"globals\"][dataset.value]\n",
    "datasetHC, datasetPC = get_datasets(options, dataset)\n",
    "config = get_config(trainer=VAE, options=options, optimizer='ADAM', intermediateResolutions=[8, 8], dropout_rate=0.1, dataset=datasetHC)\n",
    "\n",
    "# Create an instance of the model and train it\n",
    "model = VAE(tf.Session(), config, network=variational_autoencoder.variational_autoencoder)\n",
    "\n",
    "# Train it\n",
    "model.train(datasetHC)\n",
    "\n",
    "# Evaluate\n",
    "Evaluation.evaluate(datasetPC, model, options, description=f\"{type(datasetHC).__name__}-{options['threshold']}\", epoch=str(options['train']['numEpochs']))\n"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P2WmjqCqp3S4",
    "colab_type": "text"
   },
   "source": [
    "#### ceVAE - Variations\n",
    "\n",
    "Paper: [Context-encoding Variational Autoencoder for Unsupervised Anomaly Detection](https://arxiv.org/abs/1812.05941)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AsxKL2xIXhrL",
    "colab_type": "text"
   },
   "source": [
    "**CE**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Ed4PbNOc2P50",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "tf.reset_default_graph()\n",
    "dataset = Dataset.Brainweb\n",
    "options = get_options(batchsize=128, learningrate=0.0001, numEpochs=20, zDim=128, outputWidth=128, outputHeight=128, config=get_CONFIG())\n",
    "options['data']['dir'] = options[\"globals\"][dataset.value]\n",
    "datasetHC, datasetPC = get_datasets(options, dataset)\n",
    "config = get_config(trainer=CE, options=options, optimizer='ADAM', intermediateResolutions=[8, 8], dropout_rate=0.1, dataset=datasetHC)\n",
    "\n",
    "# Create an instance of the model and train it\n",
    "model = CE(tf.Session(), config, network=autoencoder.autoencoder)\n",
    "\n",
    "# Train it\n",
    "model.train(datasetHC)\n",
    "\n",
    "# Evaluate\n",
    "Evaluation.evaluate(datasetPC, model, options, description=f\"{type(datasetHC).__name__}-{options['threshold']}\", epoch=str(options['train']['numEpochs']))\n"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XlPoFhpyLgqs",
    "colab_type": "text"
   },
   "source": [
    "**ceVAE**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "7ujv7TbWVuA5",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "tf.reset_default_graph()\n",
    "dataset = Dataset.Brainweb\n",
    "options = get_options(batchsize=128, learningrate=0.0001, numEpochs=20, zDim=128, outputWidth=128, outputHeight=128, config=get_CONFIG())\n",
    "options['data']['dir'] = options[\"globals\"][dataset.value]\n",
    "datasetHC, datasetPC = get_datasets(options, dataset)\n",
    "config = get_config(trainer=ceVAE, options=options, optimizer='ADAM', intermediateResolutions=[8, 8], dropout_rate=0.1, dataset=datasetHC)\n",
    "\n",
    "config.use_gradient_based_restoration = 0.002\n",
    "\n",
    "# Create an instance of the model and train it\n",
    "model = ceVAE(tf.Session(), config, network=context_encoder_variational_autoencoder.context_encoder_variational_autoencoder)\n",
    "\n",
    "# Train it\n",
    "model.train(datasetHC)\n",
    "\n",
    "# Evaluate\n",
    "Evaluation.evaluate(datasetPC, model, options, description=f\"{type(datasetHC).__name__}-{options['threshold']}\", epoch=str(options['train']['numEpochs']))\n"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ruwGvgCnuPQ8",
    "colab_type": "text"
   },
   "source": [
    "**VAE-Zimmerer**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "rtNu_izGM8FO",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "tf.reset_default_graph()\n",
    "dataset = Dataset.BRAINWEB\n",
    "options = get_options(batchsize=64, learningrate=0.0001, numEpochs=20, zDim=128, outputWidth=128, outputHeight=128, config=get_CONFIG())\n",
    "options['data']['dir'] = options[\"globals\"][dataset.value]\n",
    "datasetHC, datasetPC = get_datasets(options, dataset)\n",
    "config = get_config(trainer=VAE, options=options, optimizer='ADAM', intermediateResolutions=[8, 8], dropout_rate=0.1, dataset=datasetHC)\n",
    "\n",
    "# Create an instance of the model and train it\n",
    "model = VAE(tf.Session(), config, network=variational_autoencoder_Zimmerer.variational_autoencoder_Zimmerer)\n",
    "\n",
    "# Train it\n",
    "model.train(datasetHC)\n",
    "\n",
    "# Evaluate\n",
    "Evaluation.evaluate(datasetPC, model, options, description=f\"{type(datasetHC).__name__}-{options['threshold']}\", epoch=str(options['train']['numEpochs']))\n"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9lhvpN6mu7QT",
    "colab_type": "text"
   },
   "source": [
    "**ceVAE-Zimmerer**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "szrN4m0eu6xM",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "tf.reset_default_graph()\n",
    "dataset = Dataset.Brainweb\n",
    "options = get_options(batchsize=64, learningrate=0.0001, numEpochs=1, zDim=128, outputWidth=128, outputHeight=128, config=get_CONFIG())\n",
    "options['data']['dir'] = options[\"globals\"][dataset.value]\n",
    "datasetHC, datasetPC = get_datasets(options, dataset)\n",
    "config = get_config(trainer=ceVAE, options=options, optimizer='ADAM', intermediateResolutions=[8, 8], dropout_rate=0.1, dataset=datasetHC)\n",
    "\n",
    "# Create an instance of the model and train it\n",
    "model = ceVAE(tf.Session(), config, network=context_encoder_variational_autoencoder_Zimmerer.context_encoder_variational_autoencoder_Zimmerer)\n",
    "\n",
    "# Train it\n",
    "model.train(datasetHC)\n",
    "\n",
    "# Evaluate\n",
    "Evaluation.evaluate(datasetPC, model, options, description=f\"{type(datasetHC).__name__}-{options['threshold']}\", epoch=str(options['train']['numEpochs']))\n"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Oc6ISRcqJMI",
    "colab_type": "text"
   },
   "source": [
    "#### GMVAE-(Restoration)-Variations\n",
    "\n",
    "Paper: [Unsupervised Lesion Detection via Image Restoration with a Normative Prior](https://openreview.net/forum?id=S1xg4W-leV)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KZmw9-2HO61B",
    "colab_type": "text"
   },
   "source": [
    "**VAE-You**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "VAF3eVrCPAdG",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "tf.reset_default_graph()\n",
    "dataset = Dataset.BRAINWEB\n",
    "options = get_options(batchsize=128, learningrate=0.0001, numEpochs=20, zDim=128, outputWidth=128, outputHeight=128, config=get_CONFIG())\n",
    "options['data']['dir'] = options[\"globals\"][dataset.value]\n",
    "datasetHC, datasetPC = get_datasets(options, dataset)\n",
    "config = get_config(trainer=VAE_You, options=options, optimizer='ADAM', intermediateResolutions=[8, 8], dropout_rate=0.1, dataset=datasetHC)\n",
    "\n",
    "config.restore_lr = 1e-3\n",
    "config.restore_steps = 10\n",
    "config.tv_lambda = 0.0\n",
    "\n",
    "# Create an instance of the model and train it\n",
    "model = VAE_You(tf.Session(), config, network=variational_autoencoder.variational_autoencoder)\n",
    "\n",
    "# Train it\n",
    "model.train(datasetHC)\n",
    "\n",
    "# Evaluate\n",
    "Evaluation.evaluate(datasetPC, model, options, description=f\"{type(datasetHC).__name__}-{options['threshold']}\", epoch=str(options['train']['numEpochs']))\n"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nhllMocWpww9",
    "colab_type": "text"
   },
   "source": [
    "**GMVAE-You**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "TmRGUPN86DTX",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "tf.reset_default_graph()\n",
    "dataset = Dataset.BRAINWEB\n",
    "options = get_options(batchsize=128, learningrate=0.0001, numEpochs=20, zDim=128, outputWidth=128, outputHeight=128, config=get_CONFIG())\n",
    "options['data']['dir'] = options[\"globals\"][dataset.value]\n",
    "datasetHC, datasetPC = get_datasets(options, dataset)\n",
    "config = get_config(trainer=GMVAE_spatial, options=options, optimizer='ADAM', intermediateResolutions=[8, 8], dropout_rate=0.1, dataset=datasetHC)\n",
    "\n",
    "config.dim_c = 9\n",
    "config.dim_z = 1\n",
    "config.dim_w = 1\n",
    "config.c_lambda = 1\n",
    "config.restore_lr = 1e-3\n",
    "config.restore_steps = 10\n",
    "config.tv_lambda = 1\n",
    "\n",
    "# Create an instance of the model and train it\n",
    "model = GMVAE_spatial(tf.Session(), config, network=gaussian_mixture_variational_autoencoder_You.gaussian_mixture_variational_autoencoder_You)\n",
    "\n",
    "# Train it\n",
    "model.train(datasetHC)\n",
    "\n",
    "# Evaluate\n",
    "Evaluation.evaluate(datasetPC, model, options, description=f\"{type(datasetHC).__name__}-{options['threshold']}\", epoch=str(options['train']['numEpochs']))\n"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "azCAeseN3t6i",
    "colab_type": "text"
   },
   "source": [
    "**GMVAE**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "o5HNY5v-qCxO",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "tf.reset_default_graph()\n",
    "dataset = Dataset.BRAINWEB\n",
    "options = get_options(batchsize=128, learningrate=0.0001, numEpochs=20, zDim=128, outputWidth=128, outputHeight=128, config=get_CONFIG())\n",
    "options['data']['dir'] = options[\"globals\"][dataset.value]\n",
    "datasetHC, datasetPC = get_datasets(options, dataset)\n",
    "config = get_config(trainer=GMVAE, options=options, optimizer='ADAM', intermediateResolutions=[8, 8], dropout_rate=0.1, dataset=datasetHC)\n",
    "\n",
    "config.dim_c = 9\n",
    "config.dim_z = 128\n",
    "config.dim_w = 1\n",
    "config.c_lambda = 1\n",
    "config.restore_lr = 1e-3\n",
    "config.restore_steps = 10\n",
    "config.tv_lambda = 0.0\n",
    "\n",
    "# Create an instance of the model and train it\n",
    "model = GMVAE(tf.Session(), config, network=gaussian_mixture_variational_autoencoder.gaussian_mixture_variational_autoencoder)\n",
    "\n",
    "# Train it\n",
    "model.train(datasetHC)\n",
    "\n",
    "# Evaluate\n",
    "Evaluation.evaluate(datasetPC, model, options, description=f\"{type(datasetHC).__name__}-{options['threshold']}\", epoch=str(options['train']['numEpochs']))"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8_GIxM1KGN2-",
    "colab_type": "text"
   },
   "source": [
    "**GMVAE-spatial**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "m9G0foovGNWI",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "tf.reset_default_graph()\n",
    "dataset = Dataset.BRAINWEB\n",
    "options = get_options(batchsize=128, learningrate=0.0001, numEpochs=20, zDim=128, outputWidth=128, outputHeight=128, config=get_CONFIG())\n",
    "options['data']['dir'] = options[\"globals\"][dataset.value]\n",
    "datasetHC, datasetPC = get_datasets(options, dataset)\n",
    "config = get_config(trainer=GMVAE_spatial, options=options, optimizer='ADAM', intermediateResolutions=[8, 8], dropout_rate=0.1, dataset=datasetHC)\n",
    "\n",
    "config.dim_c = 9\n",
    "config.dim_z = 1\n",
    "config.dim_w = 1\n",
    "config.c_lambda = 1\n",
    "config.restore_lr = 1e-3\n",
    "config.restore_steps = 10\n",
    "config.tv_lambda = 0.0\n",
    "\n",
    "# Create an instance of the model and train it\n",
    "model = GMVAE_spatial(tf.Session(), config, network=gaussian_mixture_variational_autoencoder_spatial.gaussian_mixture_variational_autoencoder_spatial)\n",
    "\n",
    "# Train it\n",
    "model.train(datasetHC)\n",
    "\n",
    "# Evaluate\n",
    "Evaluation.evaluate(datasetPC, model, options, description=f\"{type(datasetHC).__name__}-{options['threshold']}\", epoch=str(options['train']['numEpochs']))"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qdIb36bv-yji",
    "colab_type": "text"
   },
   "source": [
    "#### f-AnoGAN\n",
    "\n",
    "Paper: [f-AnoGAN: Fast unsupervised anomaly detection with generative adversarial networks.](https://www.ncbi.nlm.nih.gov/pubmed/30831356)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B3h_nH3F-0PP",
    "colab_type": "text"
   },
   "source": [
    "**Unified f-AnoGan**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "aj70VsVlAjIj",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "tf.reset_default_graph()\n",
    "dataset = Dataset.BRAINWEB\n",
    "options = get_options(batchsize=128, learningrate=0.0001, numEpochs=20, zDim=128, outputWidth=128, outputHeight=128, config=get_CONFIG())\n",
    "options['data']['dir'] = options[\"globals\"][dataset.value]\n",
    "datasetHC, datasetPC = get_datasets(options, dataset)\n",
    "config = get_config(trainer=fAnoGAN, options=options, optimizer='ADAM', intermediateResolutions=[8, 8], dropout_rate=0.1, dataset=datasetHC)\n",
    "\n",
    "config.kappa = 1.0\n",
    "config.scale = 10.0\n",
    "\n",
    "# Create an instance of the model and train it\n",
    "model = fAnoGAN(tf.Session(), config, network=fanogan.fanogan)\n",
    "\n",
    "# Train it\n",
    "model.train(datasetHC)\n",
    "\n",
    "# Evaluate\n",
    "Evaluation.evaluate(datasetPC, model, options, description=f\"{type(datasetHC).__name__}-{options['threshold']}\", epoch=str(options['train']['numEpochs']))"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JP-2nm-jYBuQ",
    "colab_type": "text"
   },
   "source": [
    "**f-AnoGAN - Schlegl**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "hclZeagWA6Rf",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "tf.reset_default_graph()\n",
    "dataset = Dataset.BRAINWEB\n",
    "options = get_options(batchsize=8, learningrate=0.0001, numEpochs=2, zDim=128, outputWidth=128, outputHeight=128, config=get_CONFIG())\n",
    "options['data']['dir'] = options[\"globals\"][dataset.value]\n",
    "datasetHC, datasetPC = get_datasets(options, dataset)\n",
    "config = get_config(trainer=fAnoGAN, options=options, optimizer='ADAM', intermediateResolutions=[16, 16], dropout_rate=0.1, dataset=datasetHC)\n",
    "\n",
    "config.kappa = 1.0\n",
    "config.scale = 10.0\n",
    "\n",
    "# Create an instance of the model and train it\n",
    "model = fAnoGAN(tf.Session(), config, network=fanogan_schlegl.fanogan_schlegl)\n",
    "\n",
    "# Train it\n",
    "model.train(datasetHC)\n",
    "\n",
    "# Evaluate\n",
    "Evaluation.evaluate(datasetPC, model, options, description=f\"{type(datasetHC).__name__}-{options['threshold']}\", epoch=str(options['train']['numEpochs']))\n"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U0D7zuB62DR0",
    "colab_type": "text"
   },
   "source": [
    "#### Constrained Adversarial AE\n",
    "\n",
    "Paper: [Unsupervised Detection of Lesions in Brain MRI using constrained adversarial auto-encoders](https://arxiv.org/abs/1806.04972)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yh6Tvwe02OWA",
    "colab_type": "text"
   },
   "source": [
    "**constrained AAE**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "YPBnr3r32LGf",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "tf.reset_default_graph()\n",
    "dataset = Dataset.BRAINWEB\n",
    "options = get_options(batchsize=128, learningrate=0.0001, numEpochs=20, zDim=128, outputWidth=128, outputHeight=128, config=get_CONFIG())\n",
    "options['data']['dir'] = options[\"globals\"][dataset.value]\n",
    "datasetHC, datasetPC = get_datasets(options, dataset)\n",
    "config = get_config(trainer=ConstrainedAAE, options=options, optimizer='ADAM', intermediateResolutions=[8, 8], dropout_rate=0.1, dataset=datasetHC)\n",
    "\n",
    "config.scale = 10.0\n",
    "config.rho = 1.0\n",
    "\n",
    "# Create an instance of the model and train it\n",
    "model = ConstrainedAAE(tf.Session(), config, network=constrained_adversarial_autoencoder.constrained_adversarial_autoencoder)\n",
    "\n",
    "# Train it\n",
    "model.train(datasetHC)\n",
    "\n",
    "# Evaluate\n",
    "Evaluation.evaluate(datasetPC, model, options, description=f\"{type(datasetHC).__name__}-{options['threshold']}\", epoch=str(options['train']['numEpochs']))\n"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5mR-WjhNv0Mo",
    "colab_type": "text"
   },
   "source": [
    "**constrained AAE Chen**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "m_HhaHSr4Of9",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "tf.reset_default_graph()\n",
    "dataset = Dataset.BRAINWEB\n",
    "options = get_options(batchsize=8, learningrate=0.0001, numEpochs=2, zDim=128, outputWidth=128, outputHeight=128, config=get_CONFIG())\n",
    "options['data']['dir'] = options[\"globals\"][dataset.value]\n",
    "datasetHC, datasetPC = get_datasets(options, dataset)\n",
    "config = get_config(trainer=ConstrainedAAE, options=options, optimizer='ADAM', intermediateResolutions=[8, 8], dropout_rate=0.1, dataset=datasetHC)\n",
    "\n",
    "config.kappa = 1.0\n",
    "config.scale = 10.0\n",
    "config.rho = 1.0\n",
    "\n",
    "# Create an instance of the model and train it\n",
    "model = ConstrainedAAE(tf.Session(), config, network=constrained_adversarial_autoencoder_Chen.constrained_adversarial_autoencoder_Chen)\n",
    "\n",
    "# Train it\n",
    "model.train(datasetHC)\n",
    "\n",
    "# Evaluate\n",
    "Evaluation.evaluate(datasetPC, model, options, description=f\"{type(datasetHC).__name__}-{options['threshold']}\", epoch=str(options['train']['numEpochs']))"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_aMjd0DR236b",
    "colab_type": "text"
   },
   "source": [
    "#### AnoVAEGAN\n",
    "\n",
    "Paper: [Deep autoencoding models for unsupervised anomaly segmentation in brain MR images](https://arxiv.org/abs/1804.04488)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "KdHKBg3B2-6W",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "tf.reset_default_graph()\n",
    "dataset = Dataset.BRAINWEB\n",
    "options = get_options(batchsize=128, learningrate=0.0001, numEpochs=20, zDim=128, outputWidth=128, outputHeight=128, config=get_CONFIG())\n",
    "options['data']['dir'] = options[\"globals\"][dataset.value]\n",
    "datasetHC, datasetPC = get_datasets(options, dataset)\n",
    "config = get_config(trainer=AnoVAEGAN, options=options, optimizer='ADAM', intermediateResolutions=[8, 8], dropout_rate=0.1, dataset=datasetHC)\n",
    "\n",
    "# Create an instance of the model and train it\n",
    "model = AnoVAEGAN(tf.Session(), config, network=anovaegan.anovaegan)\n",
    "\n",
    "# Train it\n",
    "model.train(datasetHC)\n",
    "\n",
    "# Evaluate\n",
    "Evaluation.evaluate(datasetPC, model, options, description=f\"{type(datasetHC).__name__}-{options['threshold']}\", epoch=str(options['train']['numEpochs']))\n"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "1XhjDLN73NC5",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    ""
   ],
   "execution_count": 0,
   "outputs": []
  }
 ]
}